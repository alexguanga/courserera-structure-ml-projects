{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrying out error analysis\n",
    "\n",
    "If you are training a model to find dogs and cat, we could run into some problems.\n",
    "- For example, we could have dog images that look like cats. The issue here is that we do not want to spend a lot of time figuring out if we could improve our model if it's not worth it.\n",
    "- Error Analysis:\n",
    "    - Thus, the following method offers a method to evaulate if improving the model is worth it.\n",
    "        1. Get ~100 mislabeled dev set examples\n",
    "        2. Count up how many are dogs\n",
    "        3. If only 5 percent of the mislabeled data are dogs, we know have a cieling on performance. We could only improve the error from 10% to 9.5%.\n",
    "        4. On the other hand, if we have 50% of the mislabeled data, the cieling is 50% and we could improve our error from 10% to 5%.\n",
    "        \n",
    "        \n",
    "Evaulate multiple ideas in parallel:\n",
    "- Ideas for cat detection: (the following are issues we face)\n",
    "    1. Fix pictures of dogs being recognized as cats\n",
    "    2. Fix great cats (lions, panthers, etc...) being misrecognized\n",
    "    3. Improve performance on blurry images\n",
    "- As the diagram below suggest, Andrew suggest we look at the dev images in a spreadsheet and mark the category the fit in. From there, we can tell which problem is worthwhile to work on. \n",
    "    - <img src=\"./images/struct_02.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up incorrectly labeled data\n",
    "\n",
    "Training set:\n",
    "- DL algorithms are quite robust to random errors in the training set\n",
    "- DL algorithms are not robust to systematics erros in the training set\n",
    "\n",
    "Dev/test set:\n",
    "- Work through the error analysis diagram. However, you would add a column: \"Incorrectly labeled\"\n",
    "- You should only fix it if there's a signficant percentage that are labeled incorrectly!\n",
    "- The smaller the overall dev set error, the more inclined we should be to fixing the incorrect labels keeping the incorrect labeled percentage constant. \n",
    "\n",
    "Correcting incorrect dev/test set examples\n",
    "- Apply same process to your dev and test sets to make sure they continue to come from the same distribution\n",
    "- Consider examining examples your algirithm got right as well as ones it got wrong\n",
    "- Train and dev/test data may now come from slightly different distribution\n",
    "    - It's okay not fixing all the incorrect label in the training set. The training set could come from a slightly differernt distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your first system quickly, then iterate\n",
    "\n",
    "Some issues with speech recognition example:\n",
    "- Noisy background\n",
    "- Accented speech\n",
    "- From from microphone\n",
    "- Young children's speech\n",
    "- Shuttering\n",
    "\n",
    "Recommendation:\n",
    "- Set up a dev/test set and metric\n",
    "- Build initial system quickly\n",
    "- Use Bias/Variance analysis and Error analysis to priortize next steps\n",
    "    - If during the error analysis, you realized that a lot of the error comes because the speaker is far from the microphone!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
