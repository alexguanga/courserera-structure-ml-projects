{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing human-level performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why human-level performance?\n",
    "\n",
    "Bayes optimal error: \n",
    "- The best possible error when we map from X to Y (*theoritical*)\n",
    "- <img src=\"./images/struct_01.png\" alt=\"Drawing\" style=\"width: 550px;\"/>\n",
    "- Human level performance is not that far from bayes optimal error, which can be understood from the graph.\n",
    "    - One reason performance slows after \"humans\" is that humans are good at tasks. Hence, there's not a lot of improvement after humans.\n",
    "    - Second reason is that humans can find ways to reach the human-level threshold. The following methods are effective until reaching the human-level...\n",
    "        - Humans are quite good at a a lot of tasks. So long as ML is worse than humans, you can:\n",
    "            1. Get labeled data from humans\n",
    "            2. Gain insight from manual error analysis.\n",
    "            3. Better analysis bias/variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoidable bias\n",
    "\n",
    "Example 1:\n",
    "\n",
    "| Dataset | Error | \n",
    "| --- | --- | \n",
    "| Humans | 1% |\n",
    "| Training | 8% | \n",
    "| Development | 10% | \n",
    "\n",
    "\n",
    "- **Solution**: Focus on fixing bias. We need to reduce the training error because the error term between the traiing set and humans is large. When focusing on bias, we understand the bias entails a bias across all datasets, where it won't even perform well on the training set.\n",
    "\n",
    "Example 2:\n",
    "\n",
    "| Dataset | Error | \n",
    "| --- | --- | \n",
    "| Humans | 7.5% |\n",
    "| Training | 8% | \n",
    "| Development | 10% | \n",
    "\n",
    "- **Solution**: Despite that we have a 8 training error (like in the previous example), human error is 7.5%. Hence, bias is not a problem in this example. Instead, we need to focus on lowering the dev error (*We need to focus on variance*). Variance entails that we are overfitting our dataset and hence, there's a variance among the datasets that are **NOT** the training set.\n",
    "    - Fixes: use regularization\n",
    "    - There's a greater beneifit in reducing 10 percent to 8 percent than 8 percent to 7.5 percent\n",
    "\n",
    "\n",
    "Even though we have the same training and dev error, we should focus on the human error. This can help us gauge how we approach to improve the model (either bias or variance)\n",
    "\n",
    "**Avoidable bias**: The difference or approximation of bayes error and training error. We should lower this as much as we can but performing better than bayes error is difficult. The avoidable bias can showcase what's possible and not. Even if the training error is 8%, it might be that 8% is a good error for the training set based on humans (bayes error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding human-level performance\n",
    "\n",
    "Human-level error as a proxy for Bayes error\n",
    "\n",
    "Medical image classification example:\n",
    "\n",
    "| Dataset | Error | \n",
    "| --- | --- | \n",
    "| Typical human | 3% |\n",
    "| Typical doctor | 1% | \n",
    "| Experienced doctor | 0.7% | \n",
    "| Team of experienced doctors | 0.5% | \n",
    "\n",
    "\n",
    "What is \"human-level\" error?\n",
    "- If you want a proxy for bayes error, then the bayes error should less or equal to 0.5% error.\n",
    "- Another defintion could be a typical doctor in some contexts...\n",
    "\n",
    "Error analysis example:\n",
    "\n",
    "| Dataset | Error | \n",
    "| --- | --- | \n",
    "| Human | 1%, 0.7%, 0.5% |\n",
    "| Training error | 5% | \n",
    "| Dev error | 6% | \n",
    "\n",
    "- Human (proxy for Bayes error)\n",
    "    - Btw human and training error is called the Avoidable bias\n",
    "- Training error\n",
    "    - Btw the training and dev error is called the variance\n",
    "- Dev error\n",
    "- The difference between human and training error is larger than the difference between the training and dev error\n",
    "- It does not matter the definition of the human error, you should focus on fixing the avoidable bias.\n",
    "- **Fixing on bias reduction techniques**\n",
    "\n",
    "Error analysis example:\n",
    "\n",
    "| Dataset | Error | \n",
    "| --- | --- | \n",
    "| Human | 1%, 0.7%, 0.5% |\n",
    "| Training error | 1% | \n",
    "| Dev error | 5% | \n",
    "\n",
    "- In the example above, we need to focus on decreasing the dev error (variance)\n",
    "\n",
    "If the values for human, training, and dev error are close, then we would have to choose the best accurate value for the human error (in our case, it would be 0.5%)\n",
    "\n",
    "**Summary of bias/variance with human-level performance**\n",
    "- Human-level error\n",
    "    - Proxy for bayes error\n",
    "    - Btw the human-level error and the training error is the avoidable bias\n",
    "- Training error\n",
    "    - Btw the training werror and dev error is the variance\n",
    "- Dev error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surpassing human-level performance\n",
    "\n",
    "Example:\n",
    "\n",
    "| Dataset | Error | \n",
    "| --- | --- | \n",
    "| Team of humans | 0.5% |\n",
    "| One human | 1% | \n",
    "| Training error | 0.6% | \n",
    "| Dev error | 0.8% | \n",
    "\n",
    "- Avoidable bias is 0.1% (should not use one human for bayes error, use the team of humans) and the variance is 0.2%.\n",
    "- Variance is 0.2% percent\n",
    "\n",
    "Example:\n",
    "\n",
    "| Dataset | Error | \n",
    "| --- | --- | \n",
    "| Team of humans | 0.5% |\n",
    "| One human | 1% | \n",
    "| Training error | 0.3% | \n",
    "| Dev error | 0.4% | \n",
    "\n",
    "- Notice how the training error is already better than the team of humans\n",
    "    - Thus, we have to rethink our approach since we now need to find what's the bayes error in our example\n",
    "\n",
    "\n",
    "Prior to this lecture, we were assuming that humans (experts) will outperform computers. This could be the case for image recogntion task. However, what happens when see that the training error outperforms experts.\n",
    "- **Will the human or training error by considered the bayes error?**\n",
    "\n",
    "Problems where ML signficantly surpasses human-level performance\n",
    "- The following are structured data where it's not a natural perception problem (humans tends to do well on image and speech recognition problems). \n",
    "    - Online advertising\n",
    "    - Product recommendation\n",
    "    - Logistics (predicting transite time)\n",
    "    - Loan approvals\n",
    "    \n",
    "- But even now, we ML outperforming humans in other tasks\n",
    "    - speech recognition\n",
    "    - some image recognition\n",
    "    - Medical (detecting cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model performance\n",
    "\n",
    "The two fundamental assumptions of supervised learning\n",
    "1. You can fit the training set pretty well. \n",
    "2. The training set performance generalizes pretty well to the dev/test set \n",
    "\n",
    "Reducing (avoidable) bias and variance\n",
    "1. Difference btw. human-level and training error (*avoidable bias*)\n",
    "    - Train bigger model\n",
    "        - We could train with a bigger model with hopes that the algorithm will gain better insight of the data\n",
    "    - Train longer/better optimization algorithms\n",
    "        - Momentum, RMSprop, Adam\n",
    "    - NN architecture/hyperparameters search (RNN, CNN)\n",
    "2. Difference btw. training error and dev error (*variance*)\n",
    "    - More data\n",
    "        - With more data, we are providing the algorithm with hopes that it will also learn to optimize on the dev set and not just on the training set\n",
    "    - Regularization\n",
    "        - L2, dropout, data augmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
