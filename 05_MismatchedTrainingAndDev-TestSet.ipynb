{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mismatched training and dev/test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing on different distributions\n",
    "\n",
    "\n",
    "Example: Say you have cat examples from two sources: from webpages (200,000 cat images) and the mobile app (10,000 cat images). Your job is to create a mobile application where the user can upload an image and the algorithm will detect if it's a cat or not.\n",
    "\n",
    "Option 1: Combine both datasets (for 210,000 images). Thus, we split the merged datasets into train/dev/test sets.\n",
    "- Advantage: All the sets come from the same distribution\n",
    "- Disadvantage: If we split the data into 205,000 for the training set, 2,500 for the dev and test sets, then a lot of the dev's data will come from the webpages source\n",
    "- Thus, our dev set would have 2381 images from the web. Thus, our model will be optimizing for a different distribution.\n",
    "\n",
    "Option 2: For the training set, most of the data comes from the data source you are not optimizing on.\n",
    "- In our example, Andrew suggest we have 200,000 come from the web and 5,000 from the mobile app for our training set. We would then have 5,000 for each the dev/test set.\n",
    "\n",
    "\n",
    "Another Example: Speech recognition example, Speech activated rear-view mirror!\n",
    "- Training: The data could from purchased data, smart speaker control, voice keyboard. For a total of 500,000 utterance\n",
    "- Dev/Test: smaller dataset that comes from the seppech activate rearview mirror! You have 20,000 utterance.\n",
    "- We can split the data by including some of the dev/test set in the training set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance with mismatched data distributions\n",
    "\n",
    "Cat classifier example:\n",
    "- *Assume humans have close to 0% error*\n",
    "- If you're training error is 1%, and our dev errror is 10%\n",
    "    - Then, we can assume that our model is now genealizing very well. Hence, our data is suffering from a variance issues.\n",
    "    \n",
    "New subset set: **Training-dev set**\n",
    "- Same distribution as training set, but not used for training!\n",
    "- Noticed how we would split the data from a similar distribution for the dev/test set. Well, we would do the same for the train and train/dev set. \n",
    "\n",
    "Variance:\n",
    "- Training error is 1% error.\n",
    "- Train-dev error is 9% error\n",
    "- Dev error is 10%.\n",
    "    - We could tell that we have a variance problem since the greatest change in the error came from the same distibution set!\n",
    "\n",
    "Data Mismatch:\n",
    "- Training error is 1% error\n",
    "- Train-dev error is 1.5% error\n",
    "- Dev error is 10%\n",
    "    - Here, there's a data mismatch problem because the model did not perform well on a different data distribution...  \n",
    "    - The model is performs well on the training set/training-dev set but not on the development set\n",
    "    \n",
    "Avoidable bias:\n",
    "- Human error is 0%\n",
    "- Training error is 10% error\n",
    "- Train-dev error is 11% error\n",
    "- Dev error is 12%\n",
    "    - Here, we have a high bias problem where our model is not even performing well on the training error. \n",
    "    \n",
    "Data Mismatch/Avoidable bias:\n",
    "- human error is 0%\n",
    "- Training error is 10% error\n",
    "- Train-dev error is 11% error\n",
    "- Dev error is 20%\n",
    "    - Here, we have a high bias problem and a data mismatch problem!\n",
    "    \n",
    "Bias/variance on mismatched training and dev/test sets:\n",
    "- Human level: 4%\n",
    "    - Difference btw human level error and training set error: avoidable bias!\n",
    "- Training set error: 7%\n",
    "    - Difference btw training set error and training-dev set error: variance\n",
    "- Training-dev set error: 10%\n",
    "    - Difference btw training-dev error and dev error:  variance\n",
    "- Dev error: 12%\n",
    "    - Difference btw dev error and testing error:  variance: degree of overfitting the dev set\n",
    "- Test error: 12%\n",
    "\n",
    "\n",
    "**General Formulation**\n",
    "\n",
    "| Error Level | General Speech Recognition | Rearview mirror speech data |\n",
    "| --- | --- | --- |\n",
    "| Human Level | \"Human Level\": 4% | 6% |\n",
    "| Error on examples trained on | \"Training Error\": 7% | 6% |\n",
    "| Error on examples not trained on | \"Training-dev error\": 10% | \"Dev/Test error\": 6% |\n",
    "\n",
    "Remember:\n",
    "- Human-level and training error is the avoidable bias\n",
    "- Training error and training-dev error is the variance\n",
    "- Training-dev error and dev/test error is the data mismatch\n",
    "- We have discussed various ways to improved the avoidable bias and variance. However, there are not any systematic method to improve the data mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing data mistmatch\n",
    "\n",
    "- We must figure the cause of the problem. Thus, we should carry out manual error analysis to try to understand difference between training and dev/test sets\n",
    "    - We might conclude that in our speech rearview application, that there's a lot of noise from the outside...\n",
    "- After we understand the problem, we need to focus on creating the training set distribution more similar to the dev/test distribution \n",
    "    - One way to mitigate noisy data could be to simulate noise in our in-car data\n",
    "    \n",
    "    \n",
    "At its core, the goal is to make the training set more similar to dev/test set.\n",
    "- Artifical data synthesis\n",
    "    - Like we explained above, we could add car noise to our training data to make it more similar to the in-car audio\n",
    "        1. But you must remember that this could also bring issues. If we have a lot more training data that the \"car noise\" data, then our model could overfit to the noise since we will have to recreate the car noise data for all the training data\n",
    "    - Another issues arises in image-recongition (car recongition). Let's say we are using images and replicated through graphics simulation. The issue is that your are synthesising only a sub sample of cars and recreating images with this small sub-sample that does not generalize to all cars. \n",
    "        - They are not unique cars!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
